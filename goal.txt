Autonomous Research System ‚Äì Agent Flow & Structure

## üéØ Goal of the System

Conduct **end-to-end research** on a topic:

- explore literature & ideas
- form hypotheses
- implement experiments (via Jupyter)
- analyze results
- iterate until quality threshold is met

---

## üß† Core Agents (WHO does WHAT)

### 1Ô∏è‚É£ Research Exploration Agent

**Role**

- **Build a high-quality research corpus** for future experiment execution
- **Targeted Information Gatherer**: Filter and search specifically for highly relevant papers and reports
- **Deep Dive & Filtered Ingest**: Download core PDFs and capture essential technical data (formulas, benchmarks) while excluding noise
- **No Inferencing**: Dedicated to building a lean, relevant information base without design or action responsibilities.

**Inputs**

- Research question / domain
- Previous iteration context (if any)

**Outputs**

- **Research Corpus Index**: A structured catalog of all ingested papers, notes, and technical snippets
- **Topic Summary**: A descriptive map of collected information and its location in memory
- **Raw Technical Data**: High-fidelity records available for downstream reasoning agents

**Tools**

- Web search (Tavily)
- PDF reader (download & extract text)
- Notes memory (save/search)

---

### 2Ô∏è‚É£ Experiment Design Agent

**Role**

- **Research-to-Experiment Translation**: Convert the Research Corpus into a concrete, executable experiment design.
- **Hypothesis & Variable Definition**: Formulate testable hypotheses (H‚ÇÄ, H‚ÇÅ), identify independent/dependent variables, and define controls.
- **Experimental & Statistical Specification**: Specify architectures, datasets, baselines, metrics, and the statistical analysis plan required for valid evaluation.

**Inputs**

- **User Research Goal** (Original prompt/intent) to guide the overall direction.
- **Research Corpus Index** & **Topic Summary** from the Research Agent
- Access to the **Notes Memory** (full-text PDFs and technical snippets)

**Outputs**

- **Experiment Specification**
  - Research question
  - Null & alternative hypotheses (H‚ÇÄ, H‚ÇÅ)
  - Model architectures & baselines
  - Dataset selection & preprocessing
  - Evaluation metrics
  - Statistical analysis plan (test type, Œ±, assumptions)

- **Implementation Guide**
  - Architecture constraints
  - Hyperparameter ranges
  - Training & evaluation protocol notes

**Tools & Frameworks**

- **Corpus Intelligence**:
    - **Corpus Query Tool**: Semantic search over stored notes and paper extracts.
    - **Source Cross-Referencing**: Tooling to link hypotheses to specific note IDs.
- **Experimental Logic**:
    - **Notebook Blueprinting**: Templates for structured Jupyter experimentation.
    - **Dataset Catalog**: Registry of available local and remote datasets (HuggingFace, etc.).
- **Statistical Specification Suite**:
    - **Test Selector**: Logic to choose between parametric (T-test, ANOVA) and non-parametric (Mann-Whitney, Kruskal-Wallis) tests.
    - **Power Analysis Tool**: Determining required sample sizes for statistical significance.
    - **Assumption Validator Schema**: Pre-defining the checks for Normality, Homoscedasticity, and Independence.
- **Memory**:
    - **Experiment History**: Access to results and failures of previous iterations.

---

### 3Ô∏è‚É£ Code & Notebook Agent

**Role**

- Implement experiments
- Modify code iteratively
- Work **inside a Jupyter notebook**

**Inputs**

- Experiment specification
- Feedback from Evaluation Agent

**Outputs**

- Executable notebook cells
- Training scripts
- Visualizations

**Tools**

- Jupyter kernel (critical)
- Python execution
- PyTorch / NumPy / plotting
- File system access

‚úÖ This agent **does not decide if results are good**

---

### 4Ô∏è‚É£ Execution Agent (Non-LLM / Tool Agent)

**Role**

- Run notebook cells
- Capture logs, metrics, plots
- Handle crashes / exceptions

**Inputs**

- Notebook from Code Agent

**Outputs**

- Raw results
- Error traces
- Metrics artifacts

**Tools**

- Jupyter execution
- GPU / CPU
- Runtime monitor

‚ö†Ô∏è This is often **not an LLM**, just a tool wrapper.

---

### 5Ô∏è‚É£ Evaluation / Analysis Agent

**Role**

- **Enforce Scientific Rigor**: Critically evaluate results using statistical methods.
- **Statistical Execution**: Execute the tests defined by the Design Agent.
- **Validation & Decision**: Judge **quality, correctness, and robustness** of results.
- Recommend the **next research action** based on statistical confidence.

> This agent thinks, calculates, and judges ‚Äî it does not act or execute experiment code.

---

**Inputs**

- **Analysis Protocol** from the Design Agent.
- **Evaluation artifacts**
    - Raw Metrics & results
    - Plots / logs
    - Experiment summaries
- **Research context** (Problem statement, $H_0$/$H_1$)

---

**Outputs**

- **Statistical Verdict**:
    - Calculated **p-values, confidence intervals, and effect sizes**.
    - **Assumption Check**: Verification of normality, independence, and variance ($O(n^2)$ is not what we mean here, but checking for bias).
- **Quality Score / Verdict**: 
    - `Reject H‚ÇÄ` / `Fail to reject H‚ÇÄ`
    - Decisions: `robust`, `spurious`, `promising`, `failed`.
- **Decision recommendation**: iterate, refine, or stop.
- **Rationale**: Why the results are (or aren't) statistically significant.

---

**Tools**

- Evaluation rubric
    - correctness
    - empirical signal vs noise
    - theoretical consistency
    - reproducibility
- Threshold rules
    - minimum improvement
    - max iterations
    - diminishing returns detection
- Comparison memory
    - previous experiment results
    - trend tracking

---

## üß≠ Control Layer (HOW things flow)

### Controller (Python / LangGraph)

**Responsibilities**

- Maintain global state
- Route outputs between agents
- Enforce iteration limits
- Prevent infinite loops

**State Example**

```json
{
"iteration":3,
"hypothesis":"...",
"quality_score":0.71,
"max_iterations":8,
"status":"iterate"
}
```

‚ùó This is **NOT an agent**

‚ùó This is **deterministic control**

---

## üîÅ High-Level Flow (SEQUENCE)

1. Research Exploration Agent
2. Experiment Design Agent
3. Code & Notebook Agent
4. Execution Agent
5. Evaluation & Decision Agent
6. Controller decides:
    - loop back to (2) or (3)
    - or terminate

---

## üß∞ Tool Summary (WHAT is connected)

### LLM Tools

- OpenAI Agent SDK (for agents)
- Structured outputs (JSON)

### Execution Tools

- Jupyter Notebook kernel
- Python execution
- GPU access

### Data Tools

- Dataset loaders
- File system
- Experiment logs

### Memory

- Research notes store
- Experiment history store
- Failure patterns store