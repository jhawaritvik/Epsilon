import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, List

# Try to import OpenAI for direct LLM calls (Token savings)
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

logger = logging.getLogger("ReportGenerator")

class ReportGenerator:
    """
    Generates a deterministic Markdown report by aggregating artifacts
    and using an LLM to write the narrative sections.
    """
    
    @staticmethod
    def generate(run_id: str, research_goal: str) -> str:
        """
        Compiles experiments/{run_id} into FINAL_REPORT.md
        """
        logger.info(f"Generating Final Report for Run {run_id}...")
        
        # 1. Setup Paths
        base_dir = Path(__file__).parent.parent / "experiments" / run_id
        report_path = base_dir / "FINAL_REPORT.md"
        
        if not base_dir.exists():
            return f"Error: Run directory {base_dir} does not exist."

        # 2. Load Artifacts
        dataset_meta = ReportGenerator._load_json(base_dir / "dataset_used.json")
        raw_results = ReportGenerator._load_json(base_dir / "raw_results.json")
        
        # Determine Dataset Info (Handle Procedural vs Loaded)
        ds_source = "Unknown"
        ds_type = "Unknown"
        ds_details = "{}"
        
        if dataset_meta.get("data_modality") == "procedural":
            ds_source = "Procedural Generation (Synthetic)"
            ds_type = "Synthetic Regression/Classification"
            ds_details = json.dumps(dataset_meta, indent=2)
        else:
            ds_source = dataset_meta.get('dataset_id') or dataset_meta.get('source_family', 'Unknown')
            ds_type = dataset_meta.get('type') or dataset_meta.get('requirements', {}).get('task_type', 'Unknown')
            ds_details = json.dumps(dataset_meta.get('parameters', {}), indent=2)

        # 3. Visualizations
        plots = list(base_dir.glob("*.png"))
        plot_markdown = ""
        if plots:
            plot_markdown = "## 3.1 Visualizations\n\n"
            for p in plots:
                # Use relative path for Markdown
                rel_path = p.name
                plot_markdown += f"![{p.stem}]({rel_path})\n*Figure: {p.stem}*\n\n"
        
        # 4. Generate Narrative (LLM)
        narrative = ReportGenerator._generate_narrative(research_goal, dataset_meta, raw_results)
        
        # 5. Assemble Report (Deterministic Layout)
        # NOTE: Resource metrics are in Appendix, separate from scientific conclusions
        report_content = f"""# Final Research Report
**Run ID:** `{run_id}`
**Date:** {os.getenv("DATE", "N/A")}

---

## 1. Executive Summary
{narrative.get('executive_summary', 'Summary not available.')}

## 2. Methodology
**Research Goal:** {research_goal}

### Dataset
- **Source:** {ds_source}
- **Type:** {ds_type}
- **Details:** 
```json
{ds_details}
```

{narrative.get('methodology_description', '')}

## 3. Results & Discussion
{narrative.get('results_discussion', 'See raw results below.')}

{plot_markdown}

---

## Appendix A: Artifacts & Audit Trail

### A.1 Data Artifacts
- **Raw Results:** [raw_results.json](raw_results.json)
- **Dataset Metadata:** [dataset_used.json](dataset_used.json)

### A.2 Code & Logs
- **Experiment Code:** [run_experiment.py](run_experiment.py)
- **Execution Log:** [execution.log](execution.log)

### A.3 Resource Usage
> Note: These metrics are for auditing purposes only and do not affect scientific conclusions.

| Metric | Value |
|--------|-------|
| Report Generated | {os.getenv("DATE", "N/A")} |

---
*Generated by Epsilon Autonomous Research Engine*
*Narrative sections are grounded in artifact data only. No external information was used.*
"""
        
        # 6. Save
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)
            
        logger.info(f"Report saved to {report_path}")
        
        # 7. Generate Standalone HTML
        try:
            html_path = ReportGenerator._generate_html(run_id, report_content, base_dir)
            logger.info(f"HTML Report saved to {html_path}")
        except Exception as e:
            logger.error(f"Failed to generate HTML report: {e}")
            html_path = None

        return str(report_path)

    @staticmethod
    def _generate_html(run_id: str, markdown_text: str, base_dir: Path) -> str:
        """
        Creates a standalone HTML file with professional styling.
        """
        import base64
        import re
        
        html_path = base_dir / "FINAL_REPORT.html"
        
        # Image Replacer (Logic kept in case needed, but graphs are removed from MD upstream)
        def image_replacer(match):
            alt_text = match.group(1)
            img_filename = match.group(2)
            img_path = base_dir / img_filename
            if img_path.exists():
                with open(img_path, "rb") as img_f:
                    b64_data = base64.b64encode(img_f.read()).decode("utf-8")
                    return f'<div class="figure"><img src="data:image/png;base64,{b64_data}" alt="{alt_text}"><p class="caption">Figure: {alt_text}</p></div>'
            return f""

        # Regex
        html_content = re.sub(r'!\[(.*?)\]\((.*?)\)', image_replacer, markdown_text)
        html_content = re.sub(r'(?<!!)\[(.*?)\]\((.*?)\)', r'<a href="\2" target="_blank" class="artifact-link">\1</a>', html_content)
        
        # Structural Formatting
        # Fix: Handle title at start of string (no leading newline)
        html_content = re.sub(r'(^|\n)# (.*?)(\n|$)', r'\1<h1 class="title">\2</h1>\3', html_content)
        html_content = re.sub(r'\n## (.*?)\n', r'\n<h2 class="section-header">\1</h2>\n', html_content)
        html_content = re.sub(r'\n### (.*?)\n', r'\n<h3 class="subsection-header">\1</h3>\n', html_content)
        
        # Fix: Properly handle bold (**text**) and italic (*text*) pairs
        html_content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html_content)
        html_content = re.sub(r'(?<!\*)\*(?!\*)(.*?)(?<!\*)\*(?!\*)', r'<em>\1</em>', html_content)
        
        html_content = html_content.replace("```json", "<div class='code-block'><pre><code class='json'>").replace("```", "</code></pre></div>")
        
        # Turn bullet points into styled list items
        html_content = re.sub(r'\n- (.*)', r'\n<div class="list-item">• \1</div>', html_content)
        
        # 3.4 Fix newline flattening (Semantic Paragraphs)
        html_content = re.sub(r'\n{2,}', '</p><p>', html_content)
        html_content = f"<p>{html_content}</p>"

        # 3.1 Introduce semantic blocks
        html_content = html_content.replace(
            '<h2 class="section-header">1. Executive Summary</h2>',
            '<div class="section highlight"><h2 class="section-header">1. Executive Summary</h2>'
        )
        html_content = html_content.replace(
            '<h2 class="section-header">2. Methodology</h2>',
            '</div><div class="section"><h2 class="section-header">2. Methodology</h2>'
        )
        html_content = html_content.replace(
            '<h2 class="section-header">4. Audit Trail</h2>',
            '</div><div class="section archive"><h2 class="section-header">4. Audit Trail</h2>'
        )

        # 3.3 Make metrics feel "instrumented" (Metric Cards)
        html_content = html_content.replace(
            '<h3 class="subsection-header">Quantitative Metrics</h3>',
            '<h3 class="subsection-header">Quantitative Metrics</h3>\n<div class="metric-box">'
        )
        # Close the metric box before the Audit Trail section starts (double closing div)
        html_content = html_content.replace(
            '</div><div class="section archive">', 
            '</div></div><div class="section archive">'
        )
        
        # Cyberpunk / Sci-Fi Terminal CSS
        full_html = f"""
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>EPSILON REPORT - {run_id}</title>
            <style>
                :root {{
                    --bg-color: #0d0f14;
                    --card-bg: #13161c;
                    --text-color: #c0caf5;
                    --text-muted: #565f89;
                    --accent-color: #00ffc8;  /* Cyan Neon */
                    --accent-secondary: #7aa2f7; /* Blue Neon */
                    --border-color: #24283b;
                    --font-mono: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
                    --glow: 0 0 6px rgba(0, 255, 200, 0.12);
                }}
                
                body {{
                    font-family: var(--font-mono);
                    background-color: var(--bg-color);
                    color: var(--text-color);
                    margin: 0;
                    padding: 40px;
                    line-height: 1.6;
                }}
                
                .container {{
                    max-width: 900px;
                    margin: 0 auto;
                    border: 1px solid var(--border-color);
                    padding: 40px;
                    background: var(--card-bg);
                    box-shadow: 0 0 30px rgba(0,0,0,0.5);
                    position: relative;
                    overflow: hidden;
                }}
                
                /* Decorative decorative top bar */
                .container::before {{
                    content: '';
                    position: absolute;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 2px;
                    background: linear-gradient(90deg, var(--accent-color), var(--accent-secondary));
                    box-shadow: var(--glow);
                }}

                .report-header {{
                    text-align: center;
                    border-bottom: 1px dashed var(--border-color);
                    padding-bottom: 20px;
                    margin-bottom: 40px;
                }}

                .title {{
                    font-size: 2rem;
                    text-transform: uppercase;
                    letter-spacing: 2px;
                    color: var(--accent-color);
                    margin: 0;
                    text-shadow: 0 0 5px rgba(0, 255, 200, 0.4);
                }}
                
                .run-id {{
                    display: inline-block;
                    margin-top: 10px;
                    font-size: 0.8rem;
                    color: var(--text-muted);
                    border: 1px solid var(--border-color);
                    padding: 4px 10px;
                    border-radius: 4px;
                }}

                h2, .section-header {{
                    color: var(--accent-secondary);
                    font-size: 1.4rem;
                    text-transform: uppercase;
                    padding-left: 0;
                    margin-top: 0;
                    margin-bottom: 25px;
                    letter-spacing: 1px;
                    border-left: none;
                }}
                
                h3, .subsection-header {{
                    color: #fff;
                    font-size: 1.1rem;
                    margin-top: 30px;
                }}

                p, li {{
                    font-size: 0.95rem;
                    color: #a9b1d6;
                }}

                .section {{
                    margin-bottom: 50px;
                }}

                .section.highlight {{
                    background: linear-gradient(180deg, rgba(0,255,200,0.04), transparent);
                    border-left: 3px solid var(--accent-color);
                    padding: 20px 25px;
                }}

                .section.archive {{
                    background: #0f1117;
                    border: 1px dashed var(--border-color);
                    padding: 20px;
                    opacity: 0.9;
                }}

                .metric-box {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                    gap: 15px;
                    margin: 20px 0;
                }}

                .metric-box .list-item {{
                    background: #0d0f14;
                    border: 1px solid var(--border-color);
                    padding: 15px;
                    font-size: 0.85rem;
                    list-style-type: none; 
                }}

                .code-block {{
                    background: #0f1117;
                    border: 1px solid var(--border-color);
                    padding: 15px;
                    border-radius: 4px;
                    margin: 20px 0;
                    font-size: 0.85rem;
                    overflow-x: auto;
                    color: #e0af68; /* Orange-ish for logic */
                }}
                
                /* Styled Artifact Links as "Terminal Buttons" */
                .artifact-link {{
                    display: inline-block;
                    border: 1px solid var(--accent-color);
                    color: var(--accent-color);
                    padding: 5px 15px;
                    text-decoration: none;
                    font-size: 0.8rem;
                    text-transform: uppercase;
                    margin-right: 10px;
                    transition: all 0.2s;
                }}
                
                .artifact-link:hover {{
                    background: var(--accent-color);
                    color: #000;
                    box-shadow: var(--glow);
                }}

                .figure {{
                    border: 1px solid var(--border-color);
                    background: #000;
                    padding: 10px;
                    text-align: center;
                    margin: 30px 0;
                }}
                
                .caption {{
                    color: var(--text-muted);
                    font-size: 0.8rem;
                    margin-top: 10px;
                    font-style: italic;
                }}
                
                .list-item {{
                    margin-bottom: 8px;
                    padding-left: 10px;
                    border-left: 1px solid #24283b;
                }}

                img {{
                    max-width: 100%;
                    border: 1px solid #333;
                }}
                
                .footer {{
                    margin-top: 60px;
                    padding-top: 20px;
                    border-top: 1px solid var(--border-color);
                    font-size: 0.75rem;
                    color: var(--text-muted);
                    text-align: center;
                }}

                /* Scrollbar */
                ::-webkit-scrollbar {{
                    width: 8px;
                    height: 8px;
                }}
                ::-webkit-scrollbar-track {{
                    background: #0d0f14; 
                }}
                ::-webkit-scrollbar-thumb {{
                    background: #24283b; 
                }}
                ::-webkit-scrollbar-thumb:hover {{
                    background: var(--accent-secondary); 
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="report-header">
                    <h1 class="title">Research Log</h1>
                    <span class="run-id">ID: {run_id}</span>
                </div>
                <div class="content">
                    {html_content}
                    <div class="footer">
                        EPSILON AUTONOMOUS RESEARCH ENGINE<br>
                        Deterministic • Auditable • Reproducible
                    </div>
                </div>
            </div>
        </body>
        </html>
        """
        
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(full_html)
            
        return str(html_path)

    @staticmethod
    def _load_json(path: Path) -> Dict:
        if path.exists():
            try:
                return json.loads(path.read_text(encoding="utf-8"))
            except:
                return {"error": "Invalid JSON"}
        return {}

    @staticmethod
    def _validate_results(results: Dict) -> Dict:
        """
        Validates raw_results.json to determine if intervention improved over baseline.
        Returns a validation dict with objective assessment.
        """
        validation = {
            "has_results": bool(results),
            "intervention_improved": None,
            "baseline_mean": None,
            "intervention_mean": None,
            "improvement_pct": None,
            "warning": None
        }
        
        if not results:
            validation["warning"] = "No raw results available."
            return validation
            
        # Check for test_accuracy structure (common pattern)
        test_acc = results.get("test_accuracy", {})
        if test_acc:
            baseline_key = None
            intervention_key = None
            
            # Find baseline vs intervention keys
            for key in test_acc.keys():
                lower_key = key.lower()
                if "baseline" in lower_key or "control" in lower_key:
                    baseline_key = key
                else:
                    intervention_key = key
            
            if baseline_key and intervention_key:
                import numpy as np
                baseline_vals = test_acc[baseline_key]
                intervention_vals = test_acc[intervention_key]
                
                if baseline_vals and intervention_vals:
                    validation["baseline_mean"] = float(np.mean(baseline_vals))
                    validation["intervention_mean"] = float(np.mean(intervention_vals))
                    
                    # Determine if higher is better (accuracy) or lower is better (loss)
                    # For accuracy-like metrics, intervention should be higher
                    if validation["intervention_mean"] > validation["baseline_mean"]:
                        validation["intervention_improved"] = True
                        improvement = ((validation["intervention_mean"] - validation["baseline_mean"]) 
                                      / validation["baseline_mean"]) * 100
                    else:
                        validation["intervention_improved"] = False
                        improvement = ((validation["intervention_mean"] - validation["baseline_mean"]) 
                                      / validation["baseline_mean"]) * 100
                    
                    validation["improvement_pct"] = round(improvement, 2)
                    
                    if not validation["intervention_improved"]:
                        validation["warning"] = f"INTERVENTION PERFORMED WORSE: {validation['intervention_mean']:.2f}% vs baseline {validation['baseline_mean']:.2f}%"
        
        return validation
    
    @staticmethod
    def _generate_narrative(goal: str, dataset: Dict, results: Dict) -> Dict:
        """
        Uses direct LLM call to write sections.
        Returns dict with keys: 'executive_summary', 'methodology_description', 'results_discussion'
        """
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key or not OpenAI:
            return {
                "executive_summary": "LLM generation unavailable (Missing Key or Lib).",
                "methodology_description": "See structured data above.",
                "results_discussion": "See qualitative metrics below."
            }
        
        # CRITICAL: Validate results BEFORE passing to LLM
        validation = ReportGenerator._validate_results(results)
        
        # Build validation context for LLM
        validation_context = ""
        if validation["warning"]:
            validation_context = f"""
            ⚠️ CRITICAL VALIDATION WARNING: {validation["warning"]}
            You MUST report this negative result honestly. Do NOT claim improvement where none exists.
            Baseline Mean: {validation["baseline_mean"]}
            Intervention Mean: {validation["intervention_mean"]}
            Improvement: {validation["improvement_pct"]}%
            """
        elif validation["intervention_improved"]:
            validation_context = f"""
            ✅ Validated Improvement: {validation["improvement_pct"]}%
            Baseline: {validation["baseline_mean"]:.2f}%
            Intervention: {validation["intervention_mean"]:.2f}%
            """
        else:
            validation_context = "No validation data available. Report only what can be verified from results."
            
        try:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
            You are writing a Technical Research Log for an autonomous AI engine.
            TONE: High-tech, purely analytical, concise, "Cyberpunk Scientific". Avoid fluff.
            
            GOAL: {goal}
            DATASET: {json.dumps(dataset)}
            RESULTS: {str(results)[:2000]}
            
            {validation_context}
            
            ═══════════════════════════════════════════════════════════════════════
            ██ ANTI-HALLUCINATION PROTOCOL ██
            ═══════════════════════════════════════════════════════════════════════
            
            You are STRICTLY FORBIDDEN from:
            1. Inventing numbers not present in RESULTS
            2. Claiming improvements not verified in validation_context
            3. Speculating about causes without data evidence
            4. Adding interpretations beyond what the data shows
            
            You MUST:
            1. ONLY report values that appear in the RESULTS data above
            2. Quote specific numbers when discussing metrics
            3. State "Data not available" if information is missing
            4. If intervention failed, say so directly without hedging
            5. Use phrases like "The data shows..." or "According to results..."
            
            GROUNDING CHECK: For every claim you make, you must be able to point to
            a specific value in RESULTS or DATASET. If you cannot, do not make the claim.
            ═══════════════════════════════════════════════════════════════════════
            
            Task: Write 3 sections in JSON format.
            1. "executive_summary": High-level technical abstract (approx 100 words). 
               - MUST cite specific metric values from the data
               - State explicitly whether the goal was achieved
            2. "methodology_description": Precise description of the approach (approx 50 words).
               - Reference only what is in DATASET
            3. "results_discussion": Analytical interpretation (approx 150 words).
               - Every claim must reference a specific value from RESULTS
               - If intervention failed, hypothesize why based ONLY on observed data patterns
            
            Output JSON ONLY.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            return json.loads(content)
            
        except Exception as e:
            logger.error(f"LLM Narrative Generation Failed: {e}")
            return {
                "executive_summary": f"Generation Error: {str(e)}",
                "methodology_description": "Error",
                "results_discussion": "Error"
            }
