import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, List

# Try to import OpenAI for direct LLM calls (Token savings)
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

logger = logging.getLogger("ReportGenerator")

class ReportGenerator:
    """
    Generates a deterministic Markdown report by aggregating artifacts
    and using an LLM to write the narrative sections.
    """
    
    @staticmethod
    def generate(run_id: str, research_goal: str) -> str:
        """
        Compiles experiments/{run_id} into FINAL_REPORT.md
        """
        logger.info(f"Generating Final Report for Run {run_id}...")
        
        # 1. Setup Paths
        base_dir = Path(__file__).parent.parent / "experiments" / run_id
        report_path = base_dir / "FINAL_REPORT.md"
        
        if not base_dir.exists():
            return f"Error: Run directory {base_dir} does not exist."

        # 2. Load Artifacts
        dataset_meta = ReportGenerator._load_json(base_dir / "dataset_used.json")
        raw_results = ReportGenerator._load_json(base_dir / "raw_results.json")
        summary_json = ReportGenerator._load_json(base_dir / "experiment_summary.json") # Optional
        
        # 3. Find Visuals
        plots = list(base_dir.glob("*.png"))
        plot_markdown = ""
        if plots:
            plot_markdown = "## Visualizations\n\n"
            for p in plots:
                # Use relative path for Markdown
                rel_path = p.name
                plot_markdown += f"![{p.stem}]({rel_path})\n*Figure: {p.stem}*\n\n"
        
        # 4. Generate Narrative (LLM)
        narrative = ReportGenerator._generate_narrative(research_goal, dataset_meta, raw_results)
        
        # 5. Assemble Report (Deterministic Layout)
        report_content = f"""# Final Research Report
**Run ID:** `{run_id}`
**Date:** {os.getenv("DATE", "N/A")}

---

## 1. Executive Summary
{narrative.get('executive_summary', 'Summary not available.')}

## 2. Methodology
**Research Goal:** {research_goal}

### Dataset
- **Source:** {dataset_meta.get('dataset_id', 'Unknown') or dataset_meta.get('source_family', 'Unknown')}
- **Type:** {dataset_meta.get('type') or dataset_meta.get('requirements', {}).get('task_type', 'Unknown')}
- **Details:** {json.dumps(dataset_meta.get('parameters', {}), indent=2)}

{narrative.get('methodology_description', '')}

## 3. Results & Discussion
{narrative.get('results_discussion', 'See raw results below.')}

### Quantitative Metrics
```json
{json.dumps(raw_results, indent=2)}
```

{plot_markdown}
## 4. Audit Trail
- **Code:** [run_experiment.py](run_experiment.py)
- **Logs:** [execution.log](execution.log)
- **Data:** [dataset_used.json](dataset_used.json)

---
*Generated by Epsilon Autonomous Research Engine*
"""
        
        # 6. Save
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)
            
        logger.info(f"Report saved to {report_path}")
        return str(report_path)

    @staticmethod
    def _load_json(path: Path) -> Dict:
        if path.exists():
            try:
                return json.loads(path.read_text(encoding="utf-8"))
            except:
                return {"error": "Invalid JSON"}
        return {}

    @staticmethod
    def _generate_narrative(goal: str, dataset: Dict, results: Dict) -> Dict:
        """
        Uses direct LLM call to write sections.
        Returns dict with keys: 'executive_summary', 'methodology_description', 'results_discussion'
        """
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key or not OpenAI:
            return {
                "executive_summary": "LLM generation unavailable (Missing Key or Lib).",
                "methodology_description": "See structured data above.",
                "results_discussion": "See qualitative metrics below."
            }
            
        try:
            client = OpenAI(api_key=api_key)
            
            prompt = f"""
            You are writing a Scientific Research Report.
            
            GOAL: {goal}
            DATASET: {json.dumps(dataset)}
            RESULTS: {str(results)[:2000]} # Truncated to save tokens
            
            Task: Write 3 sections in JSON format.
            1. "executive_summary": High-level overview of findings (approx 100 words).
            2. "methodology_description": Brief description of the approach (approx 50 words).
            3. "results_discussion": Interpretation of the results and effective metrics (approx 150 words).
            
            Output JSON ONLY.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            content = response.choices[0].message.content
            return json.loads(content)
            
        except Exception as e:
            logger.error(f"LLM Narrative Generation Failed: {e}")
            return {
                "executive_summary": f"Generation Error: {str(e)}",
                "methodology_description": "Error",
                "results_discussion": "Error"
            }
